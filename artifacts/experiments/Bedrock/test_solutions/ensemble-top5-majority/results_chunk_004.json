[
  {
    "id": "q227",
    "question": "True or False: The public health costs of AI are evenly distributed across communities in the U.S.",
    "gt_value": "0",
    "gt_unit": "is_blank",
    "gt_ref": "['han2024']",
    "pred_value": "0",
    "pred_unit": "is_blank",
    "pred_ref": "[\"han2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "0",
      "deepseek-r1-bench": "0",
      "llama4-maverick-bench": "0",
      "llama3-70b-bench": "0",
      "nova-pro-bench": "0"
    },
    "individual_refs": {
      "sonnet-bench": "[\"han2024\"]",
      "deepseek-r1-bench": "[\"han2024\"]",
      "llama4-maverick-bench": "[\"han2024\"]",
      "llama3-70b-bench": "[\"han2024\"]",
      "nova-pro-bench": "[\"han2024\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q228",
    "question": "True or False: As of 2019 product data, GPU theoretical performance per watt was observed to double approximately every 3-4 years.",
    "gt_value": "1",
    "gt_unit": "is_blank",
    "gt_ref": "['wu2021b']",
    "pred_value": "1",
    "pred_unit": "is_blank",
    "pred_ref": "[\"wu2021b\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1",
      "deepseek-r1-bench": "1",
      "llama4-maverick-bench": "1",
      "llama3-70b-bench": "1",
      "nova-pro-bench": "1"
    },
    "individual_refs": {
      "sonnet-bench": "[\"wu2021b\"]",
      "deepseek-r1-bench": "[\"wu2021b\"]",
      "llama4-maverick-bench": "[\"wu2021b\"]",
      "llama3-70b-bench": "[\"wu2021b\"]",
      "nova-pro-bench": "[\"wu2021b\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q229",
    "question": "Which open-source tool was specifically used to apply 4-bit quantization and support local deployment of large language models in the financial sentiment case study?",
    "gt_value": "Ollama",
    "gt_unit": "is_blank",
    "gt_ref": "['khan2025']",
    "pred_value": "Ollama",
    "pred_unit": "is_blank",
    "pred_ref": "[\"khan2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "Ollama",
      "deepseek-r1-bench": "Ollama",
      "llama4-maverick-bench": "Ollama",
      "llama3-70b-bench": "Ollama",
      "nova-pro-bench": "Ollama"
    },
    "individual_refs": {
      "sonnet-bench": "[\"khan2025\"]",
      "deepseek-r1-bench": "[\"khan2025\"]",
      "llama4-maverick-bench": "[\"khan2025\"]",
      "llama3-70b-bench": "[\"khan2025\"]",
      "nova-pro-bench": "[\"khan2025\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q232",
    "question": "What storage service was used to shard and stream datasets for spot VMs that could terminate at any time?",
    "gt_value": "Backblaze B2",
    "gt_unit": "is_blank",
    "gt_ref": "['erben2023']",
    "pred_value": "Backblaze (B2)",
    "pred_unit": "is_blank",
    "pred_ref": "[\"erben2023\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "Backblaze",
      "deepseek-r1-bench": "Backblaze (B2)",
      "llama4-maverick-bench": "Backblaze (B2)",
      "llama3-70b-bench": "WebDataset",
      "nova-pro-bench": "Backblaze (B2)"
    },
    "individual_refs": {
      "sonnet-bench": "[\"erben2023\"]",
      "deepseek-r1-bench": "[\"erben2023\"]",
      "llama4-maverick-bench": "[\"erben2023\"]",
      "llama3-70b-bench": "[\"erben2023\"]",
      "nova-pro-bench": "[\"erben2023\"]"
    },
    "value_correct": false,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q233",
    "question": "In experiments measuring inference with large language models, was the relationship between runtime and energy consumption found to be nearly linear?",
    "gt_value": "1",
    "gt_unit": "is_blank",
    "gt_ref": "['zschache2025']",
    "pred_value": "1",
    "pred_unit": "is_blank",
    "pred_ref": "[\"zschache2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1",
      "deepseek-r1-bench": "is_blank",
      "llama4-maverick-bench": "1",
      "llama3-70b-bench": "1",
      "nova-pro-bench": "1"
    },
    "individual_refs": {
      "sonnet-bench": "[\"zschache2025\"]",
      "deepseek-r1-bench": "[\"zschache2025\"]",
      "llama4-maverick-bench": "[\"zschache2025\"]",
      "llama3-70b-bench": "[\"zschache2025\"]",
      "nova-pro-bench": "[\"zschache2025\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q234",
    "question": "Which U.S. Senator introduced the AI Environmental Impacts Act bill in February 2024?",
    "gt_value": "Edward J. Markey",
    "gt_unit": "is_blank",
    "gt_ref": "['ebert2024']",
    "pred_value": "Edward J. Markey",
    "pred_unit": "is_blank",
    "pred_ref": "[\"ebert2024\", \"morrison2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "Edward J. Markey",
      "deepseek-r1-bench": "Edward J. Markey",
      "llama4-maverick-bench": "Edward J. Markey",
      "llama3-70b-bench": "Edward J. Markey",
      "nova-pro-bench": "Senator Edward J. Markey"
    },
    "individual_refs": {
      "sonnet-bench": "[\"ebert2024\"]",
      "deepseek-r1-bench": "[\"ebert2024\"]",
      "llama4-maverick-bench": "[\"ebert2024\", \"morrison2025\"]",
      "llama3-70b-bench": "[\"ebert2024\"]",
      "nova-pro-bench": "[\"ebert2024\"]"
    },
    "value_correct": true,
    "ref_score": 0.5,
    "na_correct": true
  },
  {
    "id": "q235",
    "question": "According to Chen et al. (2025), what is the price per hour for an NVIDIA H100?",
    "gt_value": "11.06",
    "gt_unit": "USD per hour",
    "gt_ref": "['chen2024']",
    "pred_value": "11.06",
    "pred_unit": "USD per hour",
    "pred_ref": "[\"chen2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "11.06",
      "deepseek-r1-bench": "11.06",
      "llama4-maverick-bench": "11.06",
      "llama3-70b-bench": "11.06",
      "nova-pro-bench": "11.06"
    },
    "individual_refs": {
      "sonnet-bench": "[\"chen2024\"]",
      "deepseek-r1-bench": "[\"chen2024\"]",
      "llama4-maverick-bench": "[\"chen2024\"]",
      "llama3-70b-bench": "[\"chen2024\"]",
      "nova-pro-bench": "[\"chen2024\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q236",
    "question": "What was the estimated average GPU lifetime (in years) before retirement in AI data centers in 2024?",
    "gt_value": "is_blank",
    "gt_unit": "years",
    "gt_ref": "is_blank",
    "pred_value": "4",
    "pred_unit": "years",
    "pred_ref": "[\"luccioni2025a\", \"morrison2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "4",
      "deepseek-r1-bench": "4",
      "llama4-maverick-bench": "4",
      "llama3-70b-bench": "4",
      "nova-pro-bench": "3.7"
    },
    "individual_refs": {
      "sonnet-bench": "[\"morrison2025\", \"luccioni2025a\"]",
      "deepseek-r1-bench": "[\"morrison2025\"]",
      "llama4-maverick-bench": "[\"morrison2025\"]",
      "llama3-70b-bench": "[\"morrison2025\"]",
      "nova-pro-bench": "[\"cottier2024\"]"
    },
    "value_correct": true,
    "ref_score": 0.0,
    "na_correct": false
  },
  {
    "id": "q237",
    "question": "What is the bare minimum number of NVIDIA V100 32GB GPUs required to run LLaMA-13B inference without compression or quantization?",
    "gt_value": "2",
    "gt_unit": "V100_32GB_GPUs",
    "gt_ref": "['samsi2024']",
    "pred_value": "2",
    "pred_unit": "V100_32GB_GPUs",
    "pred_ref": "[\"samsi2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "2",
      "deepseek-r1-bench": "2",
      "llama4-maverick-bench": "2",
      "llama3-70b-bench": "2",
      "nova-pro-bench": "2"
    },
    "individual_refs": {
      "sonnet-bench": "[\"samsi2024\"]",
      "deepseek-r1-bench": "[\"samsi2024\"]",
      "llama4-maverick-bench": "[\"samsi2024\"]",
      "llama3-70b-bench": "[\"samsi2024\"]",
      "nova-pro-bench": "[\"samsi2024\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q238",
    "question": "What are the reported GHG emissions (tCO2e) from the pre-training process for Google's Gemma family of language models, and how does this compare to the 'five cars' estimate?",
    "gt_value": "1247.61",
    "gt_unit": "tCO2e",
    "gt_ref": "['luccioni2025c']",
    "pred_value": "1247.61",
    "pred_unit": "tCO2e",
    "pred_ref": "[\"luccioni2025c\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1247.61",
      "deepseek-r1-bench": "1247.61",
      "llama4-maverick-bench": "1247.61",
      "llama3-70b-bench": "1247.61",
      "nova-pro-bench": "1247.61"
    },
    "individual_refs": {
      "sonnet-bench": "[\"luccioni2025c\"]",
      "deepseek-r1-bench": "[\"luccioni2025c\"]",
      "llama4-maverick-bench": "[\"luccioni2025c\"]",
      "llama3-70b-bench": "[\"luccioni2025c\"]",
      "nova-pro-bench": "[\"luccioni2025c\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q239",
    "question": "How long does it take to train ELMo on 3 NVIDIA GTX 1080 Ti GPUs?",
    "gt_value": "336",
    "gt_unit": "hours",
    "gt_ref": "['strubell2019']",
    "pred_value": "336",
    "pred_unit": "hours",
    "pred_ref": "[\"strubell2019\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "336",
      "deepseek-r1-bench": "336",
      "llama4-maverick-bench": "336",
      "llama3-70b-bench": "336",
      "nova-pro-bench": "336"
    },
    "individual_refs": {
      "sonnet-bench": "[\"strubell2019\"]",
      "deepseek-r1-bench": "[\"strubell2019\"]",
      "llama4-maverick-bench": "[\"strubell2019\"]",
      "llama3-70b-bench": "[\"strubell2019\"]",
      "nova-pro-bench": "[\"strubell2019\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q240",
    "question": "What is the estimated U.S. national average water consumption for electricity generation, in L/kWh?",
    "gt_value": "3.1",
    "gt_unit": "L/kWh",
    "gt_ref": "['li2025b']",
    "pred_value": "3.14",
    "pred_unit": "L/kWh",
    "pred_ref": "[\"li2025b\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "3.14",
      "deepseek-r1-bench": "3.14",
      "llama4-maverick-bench": "3.1",
      "llama3-70b-bench": "3.14",
      "nova-pro-bench": "3.1"
    },
    "individual_refs": {
      "sonnet-bench": "[\"li2025b\"]",
      "deepseek-r1-bench": "[\"li2025b\"]",
      "llama4-maverick-bench": "[\"li2025b\"]",
      "llama3-70b-bench": "[\"li2025b\", \"li2025b\"]",
      "nova-pro-bench": "[\"li2025b\"]"
    },
    "value_correct": false,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q241",
    "question": "What was the reported PUE of Google's hyperscale data centers in 2021?",
    "gt_value": "1.1",
    "gt_unit": "PUE",
    "gt_ref": "['wu2021b']",
    "pred_value": "1.1",
    "pred_unit": "PUE",
    "pred_ref": "[\"dodge2022\", \"wu2021b\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1.10",
      "deepseek-r1-bench": "1.1",
      "llama4-maverick-bench": "1.1",
      "llama3-70b-bench": "1.1",
      "nova-pro-bench": "1.10"
    },
    "individual_refs": {
      "sonnet-bench": "[\"wu2021b\"]",
      "deepseek-r1-bench": "[\"wu2021b\", \"dodge2022\"]",
      "llama4-maverick-bench": "[\"wu2021b\"]",
      "llama3-70b-bench": "[\"wu2021b\", \"dodge2022\"]",
      "nova-pro-bench": "[\"wu2021b\", \"dodge2022\", \"patterson2021\"]"
    },
    "value_correct": true,
    "ref_score": 0.5,
    "na_correct": true
  },
  {
    "id": "q242",
    "question": "According to AWS, by moving workloads from on-premises data centers to AWS in North America, what percent reduction in carbon footprint can customers typically expect?",
    "gt_value": "96",
    "gt_unit": "percent",
    "gt_ref": "['amazon2023']",
    "pred_value": "96",
    "pred_unit": "percent",
    "pred_ref": "[\"amazon2023\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "96",
      "deepseek-r1-bench": "96",
      "llama4-maverick-bench": "96",
      "llama3-70b-bench": "96",
      "nova-pro-bench": "96"
    },
    "individual_refs": {
      "sonnet-bench": "[\"amazon2023\"]",
      "deepseek-r1-bench": "[\"amazon2023\"]",
      "llama4-maverick-bench": "[\"amazon2023\"]",
      "llama3-70b-bench": "[\"amazon2023\"]",
      "nova-pro-bench": "[\"amazon2023\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q243",
    "question": "What the net cost of fine-tuning a sparse Mixtral model using 2 million queries with NVIDIA H100 GPU?",
    "gt_value": "3460",
    "gt_unit": "USD",
    "gt_ref": "['xia2024']",
    "pred_value": "3460",
    "pred_unit": "USD",
    "pred_ref": "[\"xia2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "3460",
      "deepseek-r1-bench": "3460",
      "llama4-maverick-bench": "3460",
      "llama3-70b-bench": "3460",
      "nova-pro-bench": "3460"
    },
    "individual_refs": {
      "sonnet-bench": "[\"xia2024\"]",
      "deepseek-r1-bench": "[\"xia2024\"]",
      "llama4-maverick-bench": "[\"xia2024\"]",
      "llama3-70b-bench": "[\"xia2024\"]",
      "nova-pro-bench": "[\"xia2024\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q244",
    "question": "In a typical datacenter, GPUs account for what percentage of the total provisioned power?",
    "gt_value": "[50,70]",
    "gt_unit": "percent",
    "gt_ref": "['chung2025']",
    "pred_value": "[50, 70]",
    "pred_unit": "percent",
    "pred_ref": "[\"chung2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "[50, 70]",
      "deepseek-r1-bench": "[50, 70]",
      "llama4-maverick-bench": "[50,70]",
      "llama3-70b-bench": "[50,70]",
      "nova-pro-bench": "75"
    },
    "individual_refs": {
      "sonnet-bench": "[\"chung2025\"]",
      "deepseek-r1-bench": "[\"chung2025\"]",
      "llama4-maverick-bench": "[\"chung2025\"]",
      "llama3-70b-bench": "[\"dodge2022\", \"chung2025\"]",
      "nova-pro-bench": "[\"dodge2022\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q245",
    "question": "The training infrastructure for JetMoE-8B consisted of a cluster of 12 nodes. How many total H100 GPUs were used for the training?",
    "gt_value": "96",
    "gt_unit": "H100 GPUs",
    "gt_ref": "['shen2024']",
    "pred_value": "96",
    "pred_unit": "H100 GPUs",
    "pred_ref": "[\"morrison2025\", \"shen2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "96",
      "deepseek-r1-bench": "96",
      "llama4-maverick-bench": "96",
      "llama3-70b-bench": "96",
      "nova-pro-bench": "96"
    },
    "individual_refs": {
      "sonnet-bench": "[\"shen2024\"]",
      "deepseek-r1-bench": "[\"shen2024\"]",
      "llama4-maverick-bench": "[\"shen2024\", \"morrison2025\"]",
      "llama3-70b-bench": "[\"shen2024\"]",
      "nova-pro-bench": "[\"shen2024\"]"
    },
    "value_correct": true,
    "ref_score": 0.5,
    "na_correct": true
  },
  {
    "id": "q247",
    "question": "During the first 300 logging steps of OLMo 2 7B training, what is the average GPU power for a single node while actively training?",
    "gt_value": "600",
    "gt_unit": "Watts",
    "gt_ref": "['morrison2025']",
    "pred_value": "600",
    "pred_unit": "Watts",
    "pred_ref": "[\"morrison2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "600",
      "deepseek-r1-bench": "600",
      "llama4-maverick-bench": "600",
      "llama3-70b-bench": "600",
      "nova-pro-bench": "600"
    },
    "individual_refs": {
      "sonnet-bench": "[\"morrison2025\"]",
      "deepseek-r1-bench": "[\"morrison2025\"]",
      "llama4-maverick-bench": "[\"morrison2025\"]",
      "llama3-70b-bench": "[\"morrison2025\"]",
      "nova-pro-bench": "[\"morrison2025\", \"morrison2025\", \"morrison2025\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q248",
    "question": "How many pounds of CO2e are estimated for an average human life in one year (globally)?",
    "gt_value": "11023",
    "gt_unit": "lbs",
    "gt_ref": "['strubell2019']",
    "pred_value": "11023",
    "pred_unit": "lbs",
    "pred_ref": "[\"strubell2019\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "is_blank",
      "deepseek-r1-bench": "11023",
      "llama4-maverick-bench": "11023",
      "llama3-70b-bench": "",
      "nova-pro-bench": "11023"
    },
    "individual_refs": {
      "sonnet-bench": "[\"is_blank\"]",
      "deepseek-r1-bench": "[\"strubell2019\"]",
      "llama4-maverick-bench": "[\"strubell2019\"]",
      "llama3-70b-bench": "[]",
      "nova-pro-bench": "[\"strubell2019\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q249",
    "question": "What was the approximate speedup in inference throughput for LLaMA-13B when using NVIDIA A100 GPUs compared to V100 GPUs?",
    "gt_value": "1.25",
    "gt_unit": "multiplier",
    "gt_ref": "['samsi2024']",
    "pred_value": "1.25",
    "pred_unit": "multiplier",
    "pred_ref": "[\"samsi2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1.25",
      "deepseek-r1-bench": "1.25",
      "llama4-maverick-bench": "1.25",
      "llama3-70b-bench": "1.25",
      "nova-pro-bench": "1.25"
    },
    "individual_refs": {
      "sonnet-bench": "[\"samsi2024\"]",
      "deepseek-r1-bench": "[\"samsi2024\"]",
      "llama4-maverick-bench": "[\"samsi2024\"]",
      "llama3-70b-bench": "[\"samsi2024\"]",
      "nova-pro-bench": "[\"samsi2024\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q250",
    "question": "What is the energy consumption (in Wh) of a single short query to GPT-4o?",
    "gt_value": "0.43",
    "gt_unit": "Wh",
    "gt_ref": "['jegham2025']",
    "pred_value": "0.42",
    "pred_unit": "Wh",
    "pred_ref": "[\"jegham2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "0.42",
      "deepseek-r1-bench": "0.42",
      "llama4-maverick-bench": "0.42",
      "llama3-70b-bench": "0.42",
      "nova-pro-bench": "0.42"
    },
    "individual_refs": {
      "sonnet-bench": "[\"jegham2025\"]",
      "deepseek-r1-bench": "[\"jegham2025\"]",
      "llama4-maverick-bench": "[\"jegham2025\"]",
      "llama3-70b-bench": "[\"jegham2025\"]",
      "nova-pro-bench": "[\"jegham2025\"]"
    },
    "value_correct": false,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q251",
    "question": "In the online workload experiment with a 400 TPS SLO, by approximately what percentage was the Max-Performance instance (g6e.xlarge) more expensive than InferSave's top choice?",
    "gt_value": "280",
    "gt_unit": "percent",
    "gt_ref": "['kim2025']",
    "pred_value": "280",
    "pred_unit": "percent",
    "pred_ref": "[\"kim2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "280",
      "deepseek-r1-bench": "280",
      "llama4-maverick-bench": "280",
      "llama3-70b-bench": "280",
      "nova-pro-bench": "280"
    },
    "individual_refs": {
      "sonnet-bench": "[\"kim2025\"]",
      "deepseek-r1-bench": "[\"kim2025\"]",
      "llama4-maverick-bench": "[\"kim2025\"]",
      "llama3-70b-bench": "[\"kim2025\"]",
      "nova-pro-bench": "[\"kim2025\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q252",
    "question": "Which GPU architecture was most energy-efficient for models generating only a single classification token?",
    "gt_value": "V100",
    "gt_unit": "is_blank",
    "gt_ref": "['zschache2025']",
    "pred_value": "V100 or A30",
    "pred_unit": "is_blank",
    "pred_ref": "[\"zschache2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "V100",
      "deepseek-r1-bench": "V100 or A30",
      "llama4-maverick-bench": "V100",
      "llama3-70b-bench": "V100 or A30",
      "nova-pro-bench": "V100 or A30"
    },
    "individual_refs": {
      "sonnet-bench": "[\"zschache2025\"]",
      "deepseek-r1-bench": "[\"zschache2025\"]",
      "llama4-maverick-bench": "[\"zschache2025\"]",
      "llama3-70b-bench": "[\"zschache2025\"]",
      "nova-pro-bench": "[\"zschache2025\"]"
    },
    "value_correct": false,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q254",
    "question": "True or False: Green AI involves providing the financial cost of finding, training, and running models.",
    "gt_value": "1",
    "gt_unit": "is_blank",
    "gt_ref": "['schwartz2019']",
    "pred_value": "1",
    "pred_unit": "is_blank",
    "pred_ref": "[\"schwartz2019\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1",
      "deepseek-r1-bench": "0",
      "llama4-maverick-bench": "1",
      "llama3-70b-bench": "0",
      "nova-pro-bench": "1"
    },
    "individual_refs": {
      "sonnet-bench": "[\"schwartz2019\"]",
      "deepseek-r1-bench": "[\"schwartz2019\"]",
      "llama4-maverick-bench": "[\"schwartz2019\"]",
      "llama3-70b-bench": "[\"schwartz2019\"]",
      "nova-pro-bench": "[\"schwartz2019\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q255",
    "question": "As stated in a 2025 paper, what was the total amount of electronic waste generated worldwide in the year 2022?",
    "gt_value": "62",
    "gt_unit": "metric tons",
    "gt_ref": "['luccioni2025a']",
    "pred_value": "62000000",
    "pred_unit": "metric tons",
    "pred_ref": "[\"luccioni2025a\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "62000000",
      "deepseek-r1-bench": "62000000",
      "llama4-maverick-bench": "62000000",
      "llama3-70b-bench": "62000000",
      "nova-pro-bench": "62000000"
    },
    "individual_refs": {
      "sonnet-bench": "[\"luccioni2025a\"]",
      "deepseek-r1-bench": "[\"luccioni2025a\"]",
      "llama4-maverick-bench": "[\"luccioni2025a\"]",
      "llama3-70b-bench": "[\"luccioni2025a\"]",
      "nova-pro-bench": "[\"luccioni2025a\"]"
    },
    "value_correct": false,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q256",
    "question": "(Multi-step Question) What is the difference in average system power per processor between the TPU v2 and the V100 GPU?",
    "gt_value": "104",
    "gt_unit": "Watts",
    "gt_ref": "['patterson2021']",
    "pred_value": "104",
    "pred_unit": "Watts",
    "pred_ref": "[\"patterson2021\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "104",
      "deepseek-r1-bench": "104",
      "llama4-maverick-bench": "81",
      "llama3-70b-bench": "19",
      "nova-pro-bench": "104"
    },
    "individual_refs": {
      "sonnet-bench": "[\"patterson2021\"]",
      "deepseek-r1-bench": "[\"patterson2021\"]",
      "llama4-maverick-bench": "[\"patterson2021\"]",
      "llama3-70b-bench": "[\"patterson2021\"]",
      "nova-pro-bench": "[\"patterson2021\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q257",
    "question": "How much clean freshwater can training the GPT-3 language model in Microsoft's U.S. data centers directly evaporate?",
    "gt_value": "700000",
    "gt_unit": "liters",
    "gt_ref": "['li2025b']",
    "pred_value": "700000",
    "pred_unit": "liters",
    "pred_ref": "[\"li2025b\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "700000",
      "deepseek-r1-bench": "700000",
      "llama4-maverick-bench": "700000",
      "llama3-70b-bench": "700000",
      "nova-pro-bench": "700000"
    },
    "individual_refs": {
      "sonnet-bench": "[\"li2025b\"]",
      "deepseek-r1-bench": "[\"li2025b\"]",
      "llama4-maverick-bench": "[\"li2025b\"]",
      "llama3-70b-bench": "[\"li2025b\"]",
      "nova-pro-bench": "[\"li2025b\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q258",
    "question": "How much did Facebook's recommendation and ranking model sizes increase between 2019 and 2021?",
    "gt_value": "20",
    "gt_unit": "multiplier",
    "gt_ref": "['wu2021a']",
    "pred_value": "20",
    "pred_unit": "multiplier",
    "pred_ref": "[\"wu2021a\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "20",
      "deepseek-r1-bench": "20",
      "llama4-maverick-bench": "20",
      "llama3-70b-bench": "20",
      "nova-pro-bench": "20"
    },
    "individual_refs": {
      "sonnet-bench": "[\"wu2021a\"]",
      "deepseek-r1-bench": "[\"wu2021a\"]",
      "llama4-maverick-bench": "[\"wu2021a\"]",
      "llama3-70b-bench": "[\"wu2021a\"]",
      "nova-pro-bench": "[\"wu2021a\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q259",
    "question": "Which model ranked highest in a recent eco-efficiency analysis using DEA?",
    "gt_value": "Claude-3.7 Sonnet",
    "gt_unit": "is_blank",
    "gt_ref": "['jegham2025']",
    "pred_value": "o3-mini",
    "pred_unit": "is_blank",
    "pred_ref": "[\"jegham2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "o3-mini",
      "deepseek-r1-bench": "o3-mini",
      "llama4-maverick-bench": "o3-mini",
      "llama3-70b-bench": "o3-mini",
      "nova-pro-bench": "o3-mini"
    },
    "individual_refs": {
      "sonnet-bench": "[\"jegham2025\"]",
      "deepseek-r1-bench": "[\"jegham2025\"]",
      "llama4-maverick-bench": "[\"jegham2025\"]",
      "llama3-70b-bench": "[\"jegham2025\"]",
      "nova-pro-bench": "[\"jegham2025\"]"
    },
    "value_correct": false,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q260",
    "question": "True or False: Smartphones currently average lifetimes of less than 3 years, contributing to e-waste concerns.",
    "gt_value": "1",
    "gt_unit": "is_blank",
    "gt_ref": "['wu2021b']",
    "pred_value": "1",
    "pred_unit": "is_blank",
    "pred_ref": "[\"wu2021b\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1",
      "deepseek-r1-bench": "1",
      "llama4-maverick-bench": "1",
      "llama3-70b-bench": "1",
      "nova-pro-bench": "1"
    },
    "individual_refs": {
      "sonnet-bench": "[\"wu2021b\"]",
      "deepseek-r1-bench": "[\"wu2021b\"]",
      "llama4-maverick-bench": "[\"wu2021b\"]",
      "llama3-70b-bench": "[\"wu2021b\"]",
      "nova-pro-bench": "[\"wu2021b\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q261",
    "question": "True or False: Intra-zone scaling with T4 GPUs achieved nearly linear per-GPU speedup for CV models.",
    "gt_value": "1",
    "gt_unit": "is_blank",
    "gt_ref": "['erben2023']",
    "pred_value": "1",
    "pred_unit": "is_blank",
    "pred_ref": "[\"erben2023\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "0",
      "deepseek-r1-bench": "1",
      "llama4-maverick-bench": "1",
      "llama3-70b-bench": "0",
      "nova-pro-bench": "1"
    },
    "individual_refs": {
      "sonnet-bench": "[\"erben2023\"]",
      "deepseek-r1-bench": "[\"erben2023\"]",
      "llama4-maverick-bench": "[\"erben2023\"]",
      "llama3-70b-bench": "[\"erben2023\"]",
      "nova-pro-bench": "[\"erben2023\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q264",
    "question": "What is the context window size, in tokens, for the FLM-101B model?",
    "gt_value": "2048",
    "gt_unit": "tokens",
    "gt_ref": "['li2025a']",
    "pred_value": "2048",
    "pred_unit": "tokens",
    "pred_ref": "[\"li2025a\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "2048",
      "deepseek-r1-bench": "2048",
      "llama4-maverick-bench": "2048",
      "llama3-70b-bench": "2048",
      "nova-pro-bench": "2048"
    },
    "individual_refs": {
      "sonnet-bench": "[\"li2025a\"]",
      "deepseek-r1-bench": "[\"li2025a\"]",
      "llama4-maverick-bench": "[\"li2025a\"]",
      "llama3-70b-bench": "[\"li2025a\"]",
      "nova-pro-bench": "[\"li2025a\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q265",
    "question": "True or False: LLMs generally have lower power draw during inference than diffusion models because LLM decoding is less compute-intensive and bottlenecked by VRAM bandwidth.",
    "gt_value": "1",
    "gt_unit": "is_blank",
    "gt_ref": "['chung2025']",
    "pred_value": "1",
    "pred_unit": "is_blank",
    "pred_ref": "[\"chung2025\", \"zschache2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1",
      "deepseek-r1-bench": "1",
      "llama4-maverick-bench": "1",
      "llama3-70b-bench": "1",
      "nova-pro-bench": "1"
    },
    "individual_refs": {
      "sonnet-bench": "[\"chung2025\"]",
      "deepseek-r1-bench": "[\"chung2025\"]",
      "llama4-maverick-bench": "[\"chung2025\"]",
      "llama3-70b-bench": "[\"chung2025\", \"zschache2025\"]",
      "nova-pro-bench": "[\"chung2025\"]"
    },
    "value_correct": true,
    "ref_score": 0.5,
    "na_correct": true
  },
  {
    "id": "q266",
    "question": "In 2023, what percentage of Amazon's People Managers globally identified as women?",
    "gt_value": "31.6",
    "gt_unit": "percent",
    "gt_ref": "['amazon2023']",
    "pred_value": "33.3",
    "pred_unit": "percent",
    "pred_ref": "[\"amazon2023\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "33.3",
      "deepseek-r1-bench": "50.2",
      "llama4-maverick-bench": "52.3",
      "llama3-70b-bench": "",
      "nova-pro-bench": "54.3"
    },
    "individual_refs": {
      "sonnet-bench": "[\"amazon2023\"]",
      "deepseek-r1-bench": "[\"amazon2023\"]",
      "llama4-maverick-bench": "[\"amazon2023\"]",
      "llama3-70b-bench": "[]",
      "nova-pro-bench": "[\"amazon2023\"]"
    },
    "value_correct": false,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q267",
    "question": "When excluding equity, what was the percentage range of total amortized cost attributed to computing hardware for the four key models analyzed by Cottier et al. (2025)?",
    "gt_value": "[61,76]",
    "gt_unit": "percent",
    "gt_ref": "['cottier2024']",
    "pred_value": "[61, 76]",
    "pred_unit": "percent",
    "pred_ref": "[\"[ref_id=cottier2024]\", \"cottier2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "[61, 76]",
      "deepseek-r1-bench": "[61, 76]",
      "llama4-maverick-bench": "[61, 76]",
      "llama3-70b-bench": "[61, 76]",
      "nova-pro-bench": "[61,76]"
    },
    "individual_refs": {
      "sonnet-bench": "[\"cottier2024\"]",
      "deepseek-r1-bench": "[\"cottier2024\"]",
      "llama4-maverick-bench": "[\"cottier2024\"]",
      "llama3-70b-bench": "[\"[ref_id=cottier2024]\"]",
      "nova-pro-bench": "[\"cottier2024\"]"
    },
    "value_correct": true,
    "ref_score": 0.5,
    "na_correct": true
  },
  {
    "id": "q268",
    "question": "True or False: In the financial sentiment case study, accuracy and F1 scores always improved after optimization.",
    "gt_value": "0",
    "gt_unit": "is_blank",
    "gt_ref": "['khan2025']",
    "pred_value": "0",
    "pred_unit": "is_blank",
    "pred_ref": "[\"khan2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "0",
      "deepseek-r1-bench": "0",
      "llama4-maverick-bench": "0",
      "llama3-70b-bench": "0",
      "nova-pro-bench": "0"
    },
    "individual_refs": {
      "sonnet-bench": "[\"khan2025\"]",
      "deepseek-r1-bench": "[\"khan2025\"]",
      "llama4-maverick-bench": "[\"khan2025\"]",
      "llama3-70b-bench": "[\"khan2025\"]",
      "nova-pro-bench": "[\"khan2025\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q269",
    "question": "What is the average CO2 produced, in pounds per kilowatt-hour (lbs/kWh), for power consumed in the U.S., as provided by the U.S. Environmental Protection Agency (EPA)?",
    "gt_value": "0.954",
    "gt_unit": "lbs/kWh",
    "gt_ref": "['strubell2019']",
    "pred_value": "0.954",
    "pred_unit": "lbs/kWh",
    "pred_ref": "[\"strubell2019\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "0.954",
      "deepseek-r1-bench": "0.954",
      "llama4-maverick-bench": "0.954",
      "llama3-70b-bench": "0.936",
      "nova-pro-bench": "0.954"
    },
    "individual_refs": {
      "sonnet-bench": "[\"strubell2019\"]",
      "deepseek-r1-bench": "[\"strubell2019\"]",
      "llama4-maverick-bench": "[\"strubell2019\"]",
      "llama3-70b-bench": "[\"strubell2019\"]",
      "nova-pro-bench": "[\"strubell2019\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q270",
    "question": "According to one study, what is the projected range of electricity consumption by the global AI in 2027?",
    "gt_value": "[85,134]",
    "gt_unit": "TWh",
    "gt_ref": "['li2025b']",
    "pred_value": "[85,134]",
    "pred_unit": "TWh",
    "pred_ref": "[\"[li2025b]\", \"li2025b\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "[85, 134]",
      "deepseek-r1-bench": "[85, 134]",
      "llama4-maverick-bench": "[85,134]",
      "llama3-70b-bench": "[85,134]",
      "nova-pro-bench": "[85,134]"
    },
    "individual_refs": {
      "sonnet-bench": "[\"li2025b\"]",
      "deepseek-r1-bench": "[\"li2025b\"]",
      "llama4-maverick-bench": "[\"li2025b\"]",
      "llama3-70b-bench": "[\"[li2025b]\"]",
      "nova-pro-bench": "[\"li2025b\"]"
    },
    "value_correct": true,
    "ref_score": 0.5,
    "na_correct": true
  },
  {
    "id": "q271",
    "question": "How many packages, in millions, did Amazon deliver via EVs in Europe in 2023?",
    "gt_value": "150000000",
    "gt_unit": "packages",
    "gt_ref": "['amazon2023']",
    "pred_value": "150",
    "pred_unit": "packages",
    "pred_ref": "[\"amazon2023\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "150",
      "deepseek-r1-bench": "150",
      "llama4-maverick-bench": "150",
      "llama3-70b-bench": "150",
      "nova-pro-bench": "150"
    },
    "individual_refs": {
      "sonnet-bench": "[\"amazon2023\"]",
      "deepseek-r1-bench": "[\"amazon2023\"]",
      "llama4-maverick-bench": "[\"amazon2023\"]",
      "llama3-70b-bench": "[\"amazon2023\"]",
      "nova-pro-bench": "[\"amazon2023\"]"
    },
    "value_correct": false,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q273",
    "question": "What was the total number of tokens (input + output) processed during the entire online inference workload evaluation?",
    "gt_value": "1920000",
    "gt_unit": "tokens",
    "gt_ref": "['kim2025']",
    "pred_value": "1920000",
    "pred_unit": "tokens",
    "pred_ref": "[\"kim2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1920000",
      "deepseek-r1-bench": "1920000",
      "llama4-maverick-bench": "1920000",
      "llama3-70b-bench": "1920000",
      "nova-pro-bench": "1920000"
    },
    "individual_refs": {
      "sonnet-bench": "[\"kim2025\"]",
      "deepseek-r1-bench": "[\"kim2025\"]",
      "llama4-maverick-bench": "[\"kim2025\"]",
      "llama3-70b-bench": "[\"kim2025\"]",
      "nova-pro-bench": "[\"kim2025\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q274",
    "question": "True or False: The AI Act mandates providers to disclose the greenhouse gas emissions of AI applications, such as oil and gas exploration.",
    "gt_value": "0",
    "gt_unit": "is_blank",
    "gt_ref": "['ebert2024']",
    "pred_value": "0",
    "pred_unit": "is_blank",
    "pred_ref": "[\"ebert2024\", \"luccioni2025c\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "0",
      "deepseek-r1-bench": "0",
      "llama4-maverick-bench": "0",
      "llama3-70b-bench": "0",
      "nova-pro-bench": "0"
    },
    "individual_refs": {
      "sonnet-bench": "[\"ebert2024\"]",
      "deepseek-r1-bench": "[\"ebert2024\"]",
      "llama4-maverick-bench": "[\"ebert2024\", \"luccioni2025c\"]",
      "llama3-70b-bench": "[\"ebert2024\"]",
      "nova-pro-bench": "[\"ebert2024\"]"
    },
    "value_correct": true,
    "ref_score": 0.5,
    "na_correct": true
  },
  {
    "id": "q275",
    "question": "According to the 'Flexible Start' optimization analysis in the 2022 Dodge et al. paper, what is the maximum potential percentage reduction in CO2 emissions for a short job (DenseNet 201) in the West US region?",
    "gt_value": "80",
    "gt_unit": "percent",
    "gt_ref": "['dodge2022']",
    "pred_value": "80",
    "pred_unit": "percent",
    "pred_ref": "[\"dodge2022\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "80",
      "deepseek-r1-bench": "80",
      "llama4-maverick-bench": "80",
      "llama3-70b-bench": "80",
      "nova-pro-bench": "80"
    },
    "individual_refs": {
      "sonnet-bench": "[\"dodge2022\"]",
      "deepseek-r1-bench": "[\"dodge2022\"]",
      "llama4-maverick-bench": "[\"dodge2022\"]",
      "llama3-70b-bench": "[\"dodge2022\"]",
      "nova-pro-bench": "[\"dodge2022\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q276",
    "question": "Based on findings from a 2024 study, by what factor does the energy required for the most intensive task (image generation) exceed that of the least intensive task (text classification)?",
    "gt_value": "1450",
    "gt_unit": "times",
    "gt_ref": "['luccioni2024']",
    "pred_value": "1450",
    "pred_unit": "times",
    "pred_ref": "[\"luccioni2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "1450",
      "deepseek-r1-bench": "1450",
      "llama4-maverick-bench": "1450",
      "llama3-70b-bench": "1450",
      "nova-pro-bench": "1450"
    },
    "individual_refs": {
      "sonnet-bench": "[\"luccioni2024\"]",
      "deepseek-r1-bench": "[\"luccioni2024\"]",
      "llama4-maverick-bench": "[\"luccioni2024\"]",
      "llama3-70b-bench": "[\"luccioni2024\"]",
      "nova-pro-bench": "[\"luccioni2024\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q277",
    "question": "True or False: In Yelp sentiment analysis benchmarks, traditional models achieved accuracy comparable to large language models.",
    "gt_value": "0",
    "gt_unit": "is_blank",
    "gt_ref": "['zschache2025']",
    "pred_value": "0",
    "pred_unit": "is_blank",
    "pred_ref": "[\"zschache2025\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "0",
      "deepseek-r1-bench": "0",
      "llama4-maverick-bench": "0",
      "llama3-70b-bench": "0",
      "nova-pro-bench": "0"
    },
    "individual_refs": {
      "sonnet-bench": "[\"zschache2025\"]",
      "deepseek-r1-bench": "[\"zschache2025\"]",
      "llama4-maverick-bench": "[\"zschache2025\"]",
      "llama3-70b-bench": "[\"zschache2025\"]",
      "nova-pro-bench": "[\"zschache2025\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q279",
    "question": "As of January 2024, how many Amazon Renewable Energy Projects were announced in the United States?",
    "gt_value": "244",
    "gt_unit": "projects",
    "gt_ref": "['amazon2023']",
    "pred_value": "244",
    "pred_unit": "projects",
    "pred_ref": "[\"amazon2023\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "244",
      "deepseek-r1-bench": "244",
      "llama4-maverick-bench": "244",
      "llama3-70b-bench": "244",
      "nova-pro-bench": "244"
    },
    "individual_refs": {
      "sonnet-bench": "[\"amazon2023\"]",
      "deepseek-r1-bench": "[\"amazon2023\"]",
      "llama4-maverick-bench": "[\"amazon2023\"]",
      "llama3-70b-bench": "[\"amazon2023\"]",
      "nova-pro-bench": "[\"amazon2023\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q281",
    "question": "What percent of power usage did Amazon's AWS cover with renewable energy in 2018?",
    "gt_value": "50",
    "gt_unit": "percent",
    "gt_ref": "['schwartz2019']",
    "pred_value": "is_blank",
    "pred_unit": "percent",
    "pred_ref": "[\"is_blank\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "is_blank",
      "deepseek-r1-bench": "is_blank",
      "llama4-maverick-bench": "17",
      "llama3-70b-bench": "",
      "nova-pro-bench": "17"
    },
    "individual_refs": {
      "sonnet-bench": "[\"is_blank\"]",
      "deepseek-r1-bench": "[\"is_blank\"]",
      "llama4-maverick-bench": "[\"strubell2019\"]",
      "llama3-70b-bench": "[]",
      "nova-pro-bench": "[\"strubell2019\"]"
    },
    "value_correct": false,
    "ref_score": 0.0,
    "na_correct": true
  },
  {
    "id": "q283",
    "question": "At which measurement level do the authors recommend AI energy consumption should be reported to balance accuracy and feasibility?",
    "gt_value": "Cumulative server level",
    "gt_unit": "is_blank",
    "gt_ref": "['ebert2024']",
    "pred_value": "cumulative server level",
    "pred_unit": "is_blank",
    "pred_ref": "[\"ebert2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "cumulative server level",
      "deepseek-r1-bench": "single, whole generation response to a request",
      "llama4-maverick-bench": "cumulative server level",
      "llama3-70b-bench": "Cumulative server level",
      "nova-pro-bench": "cumulative server level"
    },
    "individual_refs": {
      "sonnet-bench": "[\"ebert2024\"]",
      "deepseek-r1-bench": "[\"chung2025\"]",
      "llama4-maverick-bench": "[\"ebert2024\"]",
      "llama3-70b-bench": "[\"ebert2024\"]",
      "nova-pro-bench": "[\"ebert2024\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q284",
    "question": "In an experiment to train a BERT-base model, what percentage of the total electricity consumption was attributed to the GPU?",
    "gt_value": "74",
    "gt_unit": "percent",
    "gt_ref": "['dodge2022']",
    "pred_value": "74",
    "pred_unit": "percent",
    "pred_ref": "[\"dodge2022\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "74",
      "deepseek-r1-bench": "74",
      "llama4-maverick-bench": "74",
      "llama3-70b-bench": "74",
      "nova-pro-bench": "74"
    },
    "individual_refs": {
      "sonnet-bench": "[\"dodge2022\"]",
      "deepseek-r1-bench": "[\"dodge2022\"]",
      "llama4-maverick-bench": "[\"dodge2022\"]",
      "llama3-70b-bench": "[\"dodge2022\"]",
      "nova-pro-bench": "[\"dodge2022\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q285",
    "question": "Serving a Llama2-70b model at BF16 precision requires how many NVIDIA A100-80GB GPUs?",
    "gt_value": "2",
    "gt_unit": "NVIDIA A100-80GB GPUs",
    "gt_ref": "['griggs2024']",
    "pred_value": "2",
    "pred_unit": "NVIDIA A100-80GB GPUs",
    "pred_ref": "[\"griggs2024\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "2",
      "deepseek-r1-bench": "2",
      "llama4-maverick-bench": "",
      "llama3-70b-bench": "2",
      "nova-pro-bench": "2"
    },
    "individual_refs": {
      "sonnet-bench": "[\"griggs2024\"]",
      "deepseek-r1-bench": "[\"griggs2024\"]",
      "llama4-maverick-bench": "[]",
      "llama3-70b-bench": "[\"griggs2024\"]",
      "nova-pro-bench": "[\"griggs2024\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  },
  {
    "id": "q286",
    "question": "What was the total operational energy footprint reduction achieved at Facebook over a two-year period (2019 to 2021) due to iterative hardware-software optimization?",
    "gt_value": "28.5",
    "gt_unit": "percent",
    "gt_ref": "['wu2021a']",
    "pred_value": "28.5",
    "pred_unit": "percent",
    "pred_ref": "[\"wu2021a\"]",
    "pred_explanation": "Ensemble (answer_priority) of 5 runs: sonnet-bench, deepseek-r1-bench, llama4-maverick-bench, llama3-70b-bench, nova-pro-bench",
    "raw_response": "",
    "individual_answers": {
      "sonnet-bench": "28.5",
      "deepseek-r1-bench": "28.5",
      "llama4-maverick-bench": "28.5",
      "llama3-70b-bench": "28.5",
      "nova-pro-bench": "28.5"
    },
    "individual_refs": {
      "sonnet-bench": "[\"wu2021a\"]",
      "deepseek-r1-bench": "[\"wu2021a\"]",
      "llama4-maverick-bench": "[\"wu2021a\"]",
      "llama3-70b-bench": "[\"wu2021a\"]",
      "nova-pro-bench": "[\"wu2021a\"]"
    },
    "value_correct": true,
    "ref_score": 1.0,
    "na_correct": true
  }
]