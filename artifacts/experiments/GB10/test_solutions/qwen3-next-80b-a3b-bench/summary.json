{
  "name": "qwen3-next-80b-a3b-bench",
  "config_path": "vendor/KohakuRAG/configs/hf_qwen3_next_80b_a3b.py",
  "model_id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
  "llm_provider": "hf_local",
  "quantization": "4bit",
  "timestamp": "2026-02-16T12:14:15.035570",
  "num_questions": 282,
  "total_time_seconds": 22642.60397219658,
  "avg_latency_seconds": 80.29001805038317,
  "avg_retrieval_seconds": 15.621945475855618,
  "avg_generation_seconds": 47.8966590394365,
  "value_accuracy": 0.7943262411347518,
  "ref_overlap": 0.9086879432624113,
  "na_accuracy": 0.9375,
  "overall_score": 0.8257978723404255,
  "questions_correct": 224,
  "questions_wrong": 58,
  "error_count": 0,
  "input_tokens": 0,
  "output_tokens": 0,
  "estimated_cost_usd": 0.0,
  "hardware": {
    "gpu_vram_allocated_bytes": 73317266432,
    "gpu_vram_reserved_bytes": 75747033088,
    "gpu_vram_total_bytes": 128432373760,
    "gpu_vram_allocated_gb": 68.282,
    "gpu_vram_reserved_gb": 70.545,
    "gpu_vram_total_gb": 119.612,
    "model_disk_size_bytes": 325364487446,
    "model_disk_size_gb": 303.019,
    "model_cache_path": "/home/mlx/.cache/huggingface/hub/models--Qwen--Qwen3-Next-80B-A3B-Instruct",
    "gpu_energy_wh": 215.63121033744093,
    "gpu_avg_power_watts": 34.15512382184442,
    "gpu_peak_power_watts": 79.6,
    "gpu_power_samples": 21644,
    "model_load_time_seconds": 882.1090507507324,
    "llm_load_time_seconds": 882.1087834835052,
    "embedder_load_time_seconds": 0.00026726722717285156,
    "cpu_rss_peak_bytes": 8500428800,
    "cpu_rss_peak_gb": 7.917,
    "gpu_energy_method": "power_sampling",
    "gpu_name": "NVIDIA GB10",
    "gpu_device_id": 0,
    "gpu_count": 1,
    "cuda_version": "13.0",
    "hostname": "promaxgb10-f2e9",
    "cpu_model": "",
    "os_platform": "Linux-6.14.0-1015-nvidia-aarch64"
  },
  "config_snapshot": {
    "db": "../../data/embeddings/wattbot_jinav4.db",
    "table_prefix": "wattbot_jv4",
    "questions": "../../data/train_QA.csv",
    "output": "../../artifacts/submission_qwen3_next_80b_a3b.csv",
    "metadata": "../../data/metadata.csv",
    "llm_provider": "hf_local",
    "top_k": 8,
    "planner_max_queries": 4,
    "deduplicate_retrieval": true,
    "rerank_strategy": "combined",
    "top_k_final": 10,
    "retrieval_threshold": 0.25,
    "max_retries": 2,
    "max_concurrent": 1,
    "use_reordered_prompt": true,
    "embedding_model": "jinav4",
    "embedding_dim": 1024,
    "embedding_task": "retrieval",
    "hf_model_id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
    "hf_max_new_tokens": 512,
    "hf_temperature": 0.2,
    "_config_path": "vendor/KohakuRAG/configs/hf_qwen3_next_80b_a3b.py",
    "_run_environment": "GB10",
    "hf_dtype": "4bit",
    "_questions_file": "test_solutions.csv"
  },
  "run_environment": "GB10",
  "total_retries": 70,
  "questions_retried": 40,
  "avg_retries": 0.24822695035460993,
  "questions_file": "test_solutions.csv"
}